---
title: Type Checking Geomlab
author: Ashok Menon
abstract: |
  Lorem Ipsum.
...

```{.haskell}
```

\section{Introduction}

Lorem Ipsum.

\section{Background}

\subsection{Source Language}

In this project we will be developing a type system for \textit{Geomlab}, a dynamically typed, strict functional programming language used primarily for teaching purposes. In order to maintain focus, we will concentrate on a subset of the language (Figure\ \ref{fig:geomlab-syntax}).

\begin{figure}[htbp]
  \caption{A subset of the \textit{Geomlab} language. (i) \textit{Comments} are surrounded by curly braces and may be nested. (ii) The formal parameters of functions may be \textit{matched} against patterns. (iii) \textit{Guards}: A case of a function is evaluated only if all parameters match their patterns \textit{and} the guard expression (after the \texttt{when}) evaluates to \texttt{true}. (iv) \textit{Anonymous functions} are preceded by the \texttt{function} keyword. (v) Consecutive sequences of numbers may be generated by \textit{ranges}. (vi) \textit{List comprehensions} can be used to combine mapping, filter, and concatenation operations. (vii) Operators may be partially applied by \textit{sectioning}: \texttt{(+10)} corresponds to \texttt{function (x) x + 10}.}\label{fig:geomlab-syntax}
  \input{aux/geomlab_syntax.tex}
\end{figure}

This subset omits unification patterns (where different variables in the pattern must be bound to the same value) and $n+k$ patterns (matching numbers $m\geq k$, and binding $n\triangleq m-k$) as these features could be added as syntactic sugar on top of the existing ones without affecting the type theory.

\subsection{Expressible Values}

\begin{description}
  \item[numbers] Using a double-precision floating point representation. We sidestep the issue of operator overloading by not distinguishing between integer and floating point numbers.

  \item[strings] Finite sequences of UTF-8 encoded characters, surrounded by double quotes.

  \item[atoms] Short strings, with fast equality checks, distinguished from identiifiers by prefixing a \#.

  \item[cons cells] Pairs of values $a$ and $b$, denoted by $a:b$. These form the building blocks for compound data structures. In statically typed functional programming languages, they tend to only be used to construct singly linked-lists, but in dynamically typed languages (including \textit{Geomlab}) they are used in the construction of all product types. As we will see later, this difference will affect the direction in which we take the development of our type system.

  \item[nil] A distinguished value used to represent ``nothing'', denoted by $[]$, commonly used as the terminator for singly linked lists.

  \item[booleans] True/false values. In \textit{Geomlab} booleans are expressible but not as literals. \texttt{true} and \texttt{false} are defined in terms of the predicate \texttt{numeric}:
    \\ \texttt{define true = numeric(0);}
    \\ \texttt{define false = numeric(true);}

  \item[functions] \textit{Geomlab} has first-class multi-arity functions.
\end{description}

All categories of expressible values, barring the last two (booleans and functions) have analogous patterns that can be used to match against values in those categories.

The original language also supports hash tables and mutable reference cells which we have chosen to omit as their interaction with variance and polymorphism is a thorny issue which requires careful handling. (A story for another time.)

\subsection{Parsing}

\begin{figure}[htbp]
  \caption{\textit{Geomlab} Abstract Syntax Tree. The structure of literals are shared between that of patterns and of expressions, and so has been factored out.}\label{fig:sugar_adt}
  \input{aux/sugar.tex}
\end{figure}

We parse programs into abstract syntax trees of the $\mathbf{Sugar}$ type (Figure\ \ref{fig:sugar_adt}) which is ideal for parsing due to its similarity in structure to \textit{Geomlab}'s syntax. But, many of the nodes in $\mathbf{Sugar}$ --- corresponding to syntactic sugar --- are, in a sense, "redundant" from a typechecker's perspective. These nodes are mechanically derivable from the composition of others in $\mathbf{Sugar}$, and so in turn, the definition of the typechecker at these "sugary" nodes is derivable from its definition at other nodes. We avoid repeating this logic by \textit{desugaring} the input.

\subsection{Desugaring}

Desugaring involves replacing sugar with extensionally equivalent expressions from a restricted subset of the source language. We represent the AST after desugaring with a new type (Figure\ \ref{fig:expr_adt}) to ensure at compile-time that after desugaring, no sugar exists in the AST.

\begin{figure}[htbp]
  \caption{Type for the desugared AST.}\label{fig:expr_adt}
  \input{aux/expr.tex}
\end{figure}

List comprehensions, ranges and operator sections have been removed, and case expressions have been decoupled from function definitions into their own node (and the related \texttt{FailE} and \texttt{FallThroughE}). We also lift the restriction that only identifiers may be applied as functions. Finally, whilst in the source language patterns could be nested arbitrarily deep, in $\mathbf{Expr}$, each case expression only matches one layer (to reclaim the previous functionality, case expressions themselves are nested).

The procedure $\textit{desugar} : \mathbf{Sugar} \to \mathbf{Expr}$ treats operator sections, ranges and list comprehensions as in \textit{Geomlab}'s compiler\ \cite{Geomlab}, by converting to applications of helper functions provided by the runtime (Figure\ \ref{fig:standard-defs}), whilst the algorithm for desugaring case expressions draws inspiration from Lennart Augustsson's paper\ \cite{Augustsson:1985:CPM:5280.5303} on the techniques used to compile pattern matching in \textit{LML}, a lazy variant of \textit{ML}.

\begin{figure}
  \caption{Helper functions, as found in \textit{Geomlab}'s compiler.}\label{fig:standard-defs}
  \input{aux/standard_defs.tex}
\end{figure}

\subsection{de-Bruijn Indices}

$\mathbf{Expr}$ also alters the way local variables are introduced and denoted, using a notation referred to as \textit{de Bruijn} indices. $\mathbf{Expr}$ AST nodes that introduce new variables (like function definitions, let and case expressions) do not declare variable names, but instead simply declare how many local variables they introduce (functions introduce one for each formal parameter, let expressions always introduce one, and case expressions introduce one for every hole in the pattern). Then a reference to a local variable is denoted by the number of scopes between the reference and the scope introducing it (Figure\ \ref{fig:de_bruijn}).

\begin{figure}[htbp]
  \caption{Desugaring local variables to de-Bruijn indices.}\label{fig:de_bruijn}
  \input{aux/de_bruijn.tex}
\end{figure}

This notation has several advantages:

\begin{itemize}
  \item It tackles the issue of name shadowing (from variables inserted by the desugarer) without resorting to generating unique symbols, which requires side effectful operations.

  \item As a corollary to the first point, this makes \textit{desugar} a pure, deterministic function, which is better for testing.

  \item As the typechecker traverses the AST, it must create fresh \textit{type} variables for each local variable it encounters. These type variables can be stored in a stack, from which they can be efficiently retrieved using the local variable's de Bruijn index.

  \item When debugging output from the desugarer, free variables and bound variables are easily distinguishable in the AST.
\end{itemize}

\subsection{Source Mapping}

Explaining the system used to annotate AST nodes with source locations, for errors.

\subsection{Definitions}

Below are some basic definitions used when discussing type systems and their associated theory.

By convention, the lowercase roman alphabet denotes terms, $r,s,t,\ldots$ (and variables $x,y,z,\ldots$), the lowercase greek alphabet denotes types, $\rho,\sigma,\tau,\ldots$ (and type variables, $\alpha,\beta,\gamma,\ldots$), and the uppercase greek alphabet denotes type contexts, $\Gamma,\Delta,\ldots$

\begin{definition}[Type Context]
  A context $\Gamma$ is a partial map from variables to types. Given a context $\Gamma$, variable $x$, and a type $\sigma$, we will write $\Gamma,x : \sigma$ to denote the map $\Gamma$ with its type for $x$ overwritten with $\sigma$.
\end{definition}

\begin{definition}[Type Judgement]
  $\Gamma\vdash t :\sigma$ is a type judgement stating that assuming context $\Gamma$ there exists a proof that $t$ inhabits type $\sigma$ (in some fixed type theory).
\end{definition}

\begin{definition}[Substitution]
  $\mathbb{S}\equiv[\tau_1/\alpha_1,\ldots,\tau_n/\alpha_n]\equiv[\tau_i/\alpha_i]$ is a type substitution that, when applied to a type $\sigma$ simultaneously replaces all free occurrences of $\alpha_i$ with $\tau_i$ in $\sigma$. Application of a substitution can be written as $\mathbb{S}(\sigma)$ or equivalently $\sigma[\tau_i/\alpha_i]$.

  Substitutions can also be applied to type contexts in which case they are applied to each type in the context in turn.

  We take $\varnothing$ to denote the identity substitution.
\end{definition}

\begin{definition}[Instance]
  A type $\sigma$ is said to be an instance of another type $\tau$ iff there exists a substitution $\mathbb{S}$ s.t. $\mathbb{S}(\tau)\equiv\sigma$.
\end{definition}

\begin{definition}[Principal Type]
  Given a term in our language $t$, we say that $t$ has principal type $A$ given type context $\Gamma$ when $\Gamma\vdash t : A$ and, for any other type $A^\prime$ and context $\Delta$ s.t. $\Delta\vdash t : A^\prime$ there exists a type substitution $\mathbb{S}$ satisfying $\Delta = \mathbb{S}(\Gamma)$ and $A^\prime = \mathbb{S}(A)$.
\end{definition}

Exactly what constitutes a type and what constitutes a deduction of a type judgement differs between type theories, but the above definitions always apply.

\section{Hindley and Milner's Type System}

We begin our search with the Hindley-Milner (henceforth HM) type system\ \cite{10.2307/1995158, MILNER1978348}. This theory forms the basis of many production quality type systems, including those found in \textit{Haskell} and the \textit{ML} family of languages.

HM builds on the types in the simply-typed $\lambda$ calculus by introducing \textit{universally quantified} variables in prenex form (Definition\ \ref{def:hm-types}). This allows us to describe the types of polymorphic functions. For example, the identity function \texttt{define id(x) = x;} has principal type $\forall\alpha\ldotp(\alpha)\to\alpha$.

\begin{definition}[Types in HM]\label{def:hm-types}
  Types in our adaptation of HM are defined by:
  \begin{align*}
    \sigma & \Coloneqq~\forall\alpha\ldotp\sigma~|~\tau
    \tag*{\scriptsize(types)}
    \\\tau & \Coloneqq~\alpha~|~\iota~|~[~\tau~]~|~(~\pi~)\to\tau~|~(~)\to\tau
    \tag*{\scriptsize(quantifier-free types)}
    \\\iota & \Coloneqq~\mathbf{num}~|~\mathbf{str}~|~\mathbf{atom}~|~\mathbf{bool}
    \tag*{\scriptsize(base types)}
    \\\pi & \Coloneqq~\tau~|~\tau,\pi
    \tag*{\scriptsize(formal parameters)}
    \\\alpha & \Coloneqq~\alpha_1~|~\alpha_2~|~\cdots
    \tag*{\scriptsize(variables)}
  \end{align*}

\end{definition}

This type theory is a good starting point for many reasons: It has a reasonably efficient inference algorithm which has been proven sound and complete w.r.t the type system, the ability to specify polymorphic types affords a greater degree of flexibility, and given only a term, it is possible to infer its most general (principal) type. The last point is of particular import to us because our underlying language was originally dynamically typed, so there is no facility in the syntax to provide type annotations.

\subsection{Algorithm}

A clear exposition of a type inference algorithm for HM, Algorithm $\mathcal{W}$, is given in\ \cite{damas1982principal}, wherein it is described operating on $\lambda$ terms augmented with \texttt{let} bindings. Given a context $\Gamma$, and a term $t$, the algorithm returns a substitution $\mathbb{S}$ and type $\tau$ such that $\mathbb{S}(\Gamma)\vdash t:\tau$ is a principal deduction of $t$, if such a deduction exists (i.e. If $t$ is typeable).

As in\ \cite{damas1982principal}, we rely on Robinson's unification algorithm and the ability to produce the closure of a type with respect to a context.

\begin{definition}[Robinson's Unification Algorithm, $\mathcal{U}$]
  Given two types, $\tau$ and $\sigma$, $\mathcal{U}(\tau, \sigma) = \mathbb{U}$ where $\mathbb{U}(\tau)\equiv\mathbb{U}(\sigma)$ and $\forall\mathbb{S}\ldotp\mathbb{S}(\tau)\equiv\mathbb{S}(\sigma)\implies\exists\mathbb{S}^\prime\ldotp\mathbb{S}\equiv\mathbb{S}^\prime\mathbb{U}$ if and only if such a $\mathbb{U}$ exists.
\end{definition}

\begin{definition}[Closure]
  $\overline{\Gamma}(\tau) = \forall\alpha_1,\ldots,\alpha_n\ldotp\tau$ where $\alpha_1,\ldots,\alpha_n$ are all the variables that appear free in $\tau$ but do not appear in the domain of $\Gamma$.
\end{definition}

We extend the algorithm further, to deal with literals, recursion, sequencing, conditionals, and case expressions to create an inference algorithm for our desugared subset of \textit{Geomlab} (For convenience, we adopt a textual syntax for ASTs of type $\mathbf{Expr}$):

$(\mathbb{S},\tau)\gets\mathcal{W}(\Gamma\vdash t)$ where
\begin{enumerate}[(i)]
  \item
    \begin{enumerate}[(a)]
      \item $t$ a number, string or atom literal\hfill{\scriptsize(literal)}
        \\[.5em] $\mathbb{S}\equiv\varnothing$ and $\tau\equiv\mathbf{num}$, $\mathbf{str}$, $\mathbf{atom}$ respectively.

      \item $t\equiv[]$: $\mathbb{S}\equiv\varnothing$ and $\tau\equiv[\alpha]$ ($\alpha$ fresh).\hfill{\scriptsize(nil)}

      \item $t\equiv (h:t)$\hfill{\scriptsize(cons)}
        \\[.5em] \begin{math}
          \arraycolsep=1.5pt
          \begin{array}{llll}
            \text{let} & (\mathbb{S}_1,\tau^\prime_1) & \gets & \mathcal{W}(\Gamma\vdash h)
            \\ & (\mathbb{S}_2,\tau^\prime_2) & \gets & \mathcal{W}(\mathbb{S}_1(\Gamma)\vdash t)
            \\ & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\tau^\prime_2,[\mathbb{S}_2(\tau^\prime_1)])
          \end{array}
        \end{math}
      \\[.5em] $\mathbb{S}\equiv\mathbb{US}_2\mathbb{S}_1$ and $\tau\equiv\mathbb{U}(\tau^\prime_2)$
    \end{enumerate}

  \item $t\equiv x\land x:\forall\alpha_1\ldots\alpha_n\ldotp\tau^\prime\in\Gamma$\hfill{\scriptsize(variables)}
    \\[.5em] $\mathbb{S}\equiv\varnothing$ and $\tau\equiv\tau^\prime[\beta_i/\alpha_i]$ ($\beta_i$ fresh).

  \item $t\equiv f(e_1,\ldots,e_k)$\hfill{\scriptsize(function applications)}
    \\[.5em] \begin{math}
      \arraycolsep=1.5pt
      \begin{array}{llll}
        \text{let} & (\mathbb{S}_0,\tau^\prime_0) & \gets & \mathcal{W}(\Gamma\vdash f)
        \\ & (\mathbb{S}_i,\tau^\prime_i) & \gets & \mathcal{W}(\mathbb{S}_{i-1}\ldots\mathbb{S}_{0}(\Gamma)\vdash e_i)
        \\ & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\mathbb{S}_k\ldots\mathbb{S}_1(\tau^\prime_0), (\tau^\prime_1,\ldots,\tau^\prime_k)\to\beta) \text{ ($\beta$ fresh)}
      \end{array}
    \end{math}
    \\[.5em] $\mathbb{S}\equiv\mathbb{U}\mathbb{S}_k\ldots\mathbb{S}_0$ and $\tau\equiv\mathbb{U}(\beta)$.

  \item $t\equiv \texttt{function ($x_1,\ldots,x_k$) $e$}$\hfill{\scriptsize(abstractions)}
    \\[.5em] let $(\mathbb{S}^\prime,\tau^\prime)\gets\mathcal{W}(\Gamma,x_1:\beta_1,\ldots,x_k:\beta_k\vdash e)$ ($\beta_i$ fresh)
    \\[.5em] $\mathbb{S}\equiv\mathbb{S}^\prime$ and $\tau\equiv(\mathbb{S}^\prime(x_1),\ldots,\mathbb{S}^\prime(x_k))\to\tau^\prime$

  \item $t\equiv \texttt{let $x$ = $e_1$ in $e_2$}$\hfill{\scriptsize(\textit{recursive} let expressions)}
    \\[.5em] \begin{math}
    \arraycolsep=1.5pt
    \begin{array}{llll}
      \text{let} & (\mathbb{S}_1,\tau_1) & \gets & \mathcal{W}(\Gamma,x:\beta\vdash e_1) \text{ ($\beta$ fresh)}
      \\ & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\mathbb{S}_1(\beta), \tau_1)
      \\ & \phantom{(}\Gamma^\prime,~\tau^\prime_1 & \gets & \mathbb{US}_1(\Gamma),~\mathbb{U}(\tau_1)
      \\ & (\mathbb{S}_2, \tau_2) & \gets & \mathcal{W}(\Gamma^\prime,x:\overline{\Gamma^\prime}(\tau^\prime_1)\vdash e_2)
    \end{array}
    \end{math}
    \\[.5em] $\mathbb{S}\equiv\mathbb{S}_2\mathbb{US}_1$ and $\tau\equiv\tau_2$

  \item $t\equiv e_1~\texttt{>>}~e_2$\hfill{\scriptsize(sequencing)}
    \\[.5em] \begin{math}
    \arraycolsep=1.5pt
    \begin{array}{llll}
      \text{let} & (\mathbb{S}_1,\tau_1) & \gets & \mathcal{W}(\Gamma\vdash e_1)
      \\ & (\mathbb{S}_2, \tau_2) & \gets & \mathcal{W}(\mathbb{S}_1(\Gamma)\vdash e_2)
    \end{array}
    \end{math}
    \\[.5em] $\mathbb{S}\equiv\mathbb{S}_2\mathbb{S}_1$ and $\tau\equiv\tau_2$.

  \item $t\equiv \texttt{if $e_1$ then $e_2$ else $e_3$}$\hfill{\scriptsize(conditionals)}
    \\[.5em] \begin{math}
    \arraycolsep=1.5pt
    \begin{array}{llll}
      \text{let} & (\mathbb{S}_1,\tau_1) & \gets & \mathcal{W}(\Gamma\vdash e_1)
      \\ & (\mathbb{S}_2, \tau_2) & \gets & \mathcal{W}(\mathbb{S}_1(\Gamma)\vdash e_2)
      \\ & (\mathbb{S}_3, \tau_3) & \gets & \mathcal{W}(\mathbb{S}_2\mathbb{S}_1(\Gamma)\vdash e_3)
      \\ & \phantom{(} \mathbb{U}_1 & \gets & \mathcal{U}(\mathbb{S}_3\mathbb{S}_2(\tau_1),\mathbf{bool})
      \\ & \phantom{(} \mathbb{U}_2 & \gets & \mathcal{U}(\mathbb{U}_1\mathbb{S}_3\mathbb{S}_2(\tau_2), \mathbb{U}_1\mathbb{S}_3\mathbb{S}_2(\tau_3))
    \end{array}
    \end{math}
    \\[.5em] $\mathbb{S}\equiv\mathbb{U}_2\mathbb{U}_1\mathbb{S}_3\mathbb{S}_2\mathbb{S}_1$ and $\tau\equiv\mathbb{U}_2\mathbb{U}_1\mathbb{S}_3\mathbb{S}_2(\tau_2)$.

  \item $t\equiv \texttt{case $c$ of } pat_1\to e_1;\cdots ;pat_k\to e_k$\hfill{\scriptsize(case expressions)}
    \\[.5em] \begin{math}
    \arraycolsep=1.5pt
    \begin{array}{llll}
      \text{let} & (\mathbb{S}_0,\tau_0) & \gets & \mathcal{W}(\Gamma\vdash c)
      \\ & (\mathbb{S}_i, \tau_i) & \gets & \mathcal{P}(pat_i, e_i)
      \\ & \phantom{(}\rho_i & \gets & \mathbb{S}_{i-1}\ldots\mathbb{S}_1(\tau_0)
      \\ & \phantom{(}\Delta_i & \gets & \mathbb{S}_{i-1}\ldots\mathbb{S}_1(\Gamma)
    \end{array}
    \end{math}

    $\mathbb{S}\equiv\mathbb{S}_k\ldots\mathbb{S}_1$ and $\tau\equiv\tau_k$.\\
    Where $\mathcal{P}(pat_i, e_i)$ is defined as:
    \begin{enumerate}[(a)]
    \item $pat_i$ a numeric, string or atom literal pattern\hfill{\scriptsize(literal pattern)}
      \\[.2em] \begin{math}
        \arraycolsep=1.5pt
        \begin{array}{llll}
          \text{let} & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\rho_i,\mathbf{num})\text{ ($\mathbf{str}$, $\mathbf{atom}$ respectively)}
          \\ & (\mathbb{S}^\prime,\tau^\prime) & \gets & \mathcal{W}(\mathbb{U}(\Delta_i)\vdash e_i)
          \\ & \phantom{(}\mathbb{U}^\prime & \gets & \mathcal{U}(\mathbb{S}^\prime\mathbb{U}(\tau_{i-1}), \tau^\prime)
        \end{array}
      \end{math}
      \\[.2em] $\mathbb{S}_i\equiv\mathbb{U}^\prime\mathbb{S}^\prime\mathbb{U}$ and $\tau_i\equiv\mathbb{U}^\prime(\tau^\prime)$

    \item $pat_i\equiv[]$\hfill{\scriptsize(nil pattern)}
      \\[.2em] \begin{math}
        \arraycolsep=1.5pt
        \begin{array}{llll}
          \text{let} & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\rho_i,[\alpha])\text{ ($\alpha$ fresh) }
          \\ & (\mathbb{S}^\prime,\tau^\prime) & \gets & \mathcal{W}(\mathbb{U}(\Delta_i)\vdash e_i)
          \\ & \phantom{(}\mathbb{U}^\prime & \gets & \mathcal{U}(\mathbb{S}^\prime\mathbb{U}(\tau_{i-1}), \tau^\prime)
        \end{array}
      \end{math}
      \\[.2em] $\mathbb{S}_i\equiv\mathbb{U}^\prime\mathbb{S}^\prime\mathbb{U}$ and $\tau_i\equiv\mathbb{U}^\prime(\tau^\prime)$

    \item $pat_i\equiv(h:t)$\hfill{\scriptsize(cons pattern)}
      \\[.2em] \begin{math}
        \arraycolsep=1.5pt
        \begin{array}{llll}
          \text{let} & \phantom{(}\mathbb{U} & \gets & \mathcal{U}(\rho_i,[\alpha])\text{ ($\alpha$ fresh)}
          \\ & (\mathbb{S}^\prime,\tau^\prime) & \gets & \mathcal{W}(\mathbb{U}(\Delta_i,h:\alpha,t:[\alpha])\vdash e_i)
          \\ & \phantom{(}\mathbb{U}^\prime & \gets & \mathcal{U}(\mathbb{S}^\prime\mathbb{U}(\tau_{i-1}), \tau^\prime)
        \end{array}
      \end{math}
      \\[.2em] $\mathbb{S}_i\equiv\mathbb{U}^\prime\mathbb{S}^\prime\mathbb{U}$ and $\tau_i\equiv\mathbb{U}^\prime(\tau^\prime)$
    \end{enumerate}
\end{enumerate}

\subsection{Implementation}

\text{Na\"ive} implementations of this algorithm --- in which types are represented as strings and all operations are performed eagerly --- tend to exhibit poor performance. Whilst inference for HM is known to be \textsc{DExpTime-Complete}\ \cite{kfoury90mlexptime}, such a worst-case running time can be avoided in all but the pathalogical cases. We use techniques from Oleg Kiselyov's tutorial on the implementation of \textit{OCaml}'s type inference algorithm\ \cite{oleg13ocamltc} to improve the performance of our algorithm in typical cases.

\subsubsection{Unification}

We represent types with acyclic graphs, and make unification a side-effectful operation, modifying types in place instead of returning a unifier. This allows for structural sharing, and makes unification cheaper: If we are unifying a variable in one type with another type, we replace the node representing the variable in the former with a forward pointer to the latter, a much cheaper operation than string substitution. Long chains of forward pointers that may arise are also compressed as they are traversed.

In this representation, cyclic types present as cycles of pointers. As a result, the algorithm is at risk of looping infinitely, unless we detect such features. We do so by leaving breadcrumbs at every node we enter and removing them once we make our way back. If we find a crumb at a node we have just entered, we know we have doubled back on ourselves. In such a situation, it is appropriate to throw an error as cyclic types are not valid in the HM theory.

\subsubsection{Generalisation}

Another target for improvement is \textit{generalisation}: When type checking a \texttt{let} expression or top-level definition, $e$, after inferring a type for the expression being defined, we take its \textit{closure} by universally quantifying any remaining free variables (see the algorithm above) --- The variables quantified by this process are said to be \textit{owned} by $e$.

A \text{na\"ive} algorithm traverses the entire type being closed over, searching for unbound variables. To prune the traversal, we annotate each type with a \textit{level}, associating it with a \texttt{let} expression or definition node: A \texttt{let} expression's level increases with nesting (cf. de-Bruijn indices, but limited to other \texttt{let} expressions). Variables are annotated with the level of the expression that owns them, and compound types are annotated with the max level of any variable they mention. Then when closing over a type for a definition at level $l$, we only traverse compound types with level $l^\prime$ if $l^\prime\geq l$.

\subsubsection{Instantiation}

We can extend this pruning approach to also deal with \textit{instantiation}: The process of replacing quantified (type) variables with fresh (type) variables, done when type checking a bound (term) variable; In some senses an inverse of \textit{generalisation}.

By annotating types with a flag that is true when the type contains a quantified variable, when traversing for instantiation, we need only look at types where this flag is set. In our implementation, instead of a flag we use a special level, call it $\top$, such that for all levels $l\in\mathbb{N}$, $l<\top$. As we generalise a type, every variable we touch has its level set to $\top$, the rules for propogating levels to compound types takes care of the rest.

\subsubsection{Level Adjustments}

Unification can reduce the level of a type, which means we must work to keep levels consistent after unifications. For compound types, this would involve updating all mentioned variables with the lower level (if doing so lowers the variable's level), and propagating the change back up. Instead of doing this as we unify, we may instead perform this book-keeping lazily: If we unify a compound type we annotate it with the new level that should be propagated to its leaves, and push it onto a queue of types waiting to be adjusted. Just before we perform a generalisation, we force these waiting adjustments (as they could affect the generalisation outcome). Type variables, having no children, can still have their levels updated eagerly.

When we force waiting adjustments, we are doing so because a type whose level was once greater than the level we are generalising at could receive a lower level and escape being quantified. So, going a step further, we could force adjustments only when the type's current level is greater than the definition expression's level, and replace those at lower levels to be forced at a later stage.

\subsubsection{Type Syntax}

Our final consideration is not one of performance, but of formatting. Types as returned by our typechecker will use identifiers prefixed by an apostrophe to denote type variables, all of which are implicitly universally quantified. Additionally, when there is only one parameter to a function, the parenthesese are omitted for brevity, so $\forall\alpha\ldotp(\alpha)\to\alpha$ becomes ${\texttt{'a -> 'a}}$.

\subsection{Examples}

We now look at the action of our desugarer and typechecker on some small \textit{Geomlab} programs.

\subsubsection{\cmark~Basic Type Inference}

\HMExample{\texttt{(+10);}}{\input{aux/section_ast.tex}}{\texttt{num -> num}}

The algorithm arrives at the type for this expression by desugaring the operator section into an application of \texttt{\_rsect} applied to \texttt{+} and its second argument, when supplied with the appropriate types:

\texttt{%
  \_rsect :: (('a, 'b) -> 'c, 'b) -> 'a -> 'c\\
  + :: (num, num) -> num%
}

We provide these as part of the context in which every expression is typed, as they are built-in definitions.

\subsubsection{\xmark~Basic Type Error}

\HMExample{\texttt{"foo"+"bar";}}{\input{aux/string_add.tex}}{\input{aux/string_add_err.tex}}

\textit{Geomlab} has separate operators for the addition of numbers (\texttt{+}) and the concatenation of strings (\texttt{\^}). The assumption made by the programmer here is that \texttt{+} is overloaded to deal with both, which the typechecker catches as a unification error (in this case, between \texttt{num} and \texttt{str}, which are not unifiable because they are distinct base types).


Without further context finding the source of the error is quite difficult. To help, we also provide the outermost types that were being unified at the time of the error, as these are usually what correspond to expressions in the source language. In this case, these are ${\texttt{(num, num) -> num}}$ --- the type of \texttt{+} --- and ${\texttt{(str, str) -> 'a}}$ --- a constraint on the type the programmer expected of \texttt{+}.

\subsubsection{\xmark~Arity Mismatch}

\HMExample{\texttt{let k(x, y) = x in k(1);}}{\input{aux/arity_mismatch.tex}}{\input{aux/arity_mismatch_err.tex}}

Unlike \textit{Haskell}, Multi-arity functions in \textit{Geomlab} are not curried by default, and as a result, they cannot be partially applied. The type system captures this constraint as a unification error.

\subsubsection{\xmark~Branch Unification}

\HMExample{\texttt{if true then 1 else "foo";}}{\input{aux/branch_unify.tex}}{\input{aux/branch_unify_err.tex}}

In order to assign a type to a conditional, we require that the \textit{then} and \textit{else} expression types are unifiable, but this is not \textit{necessary}. In this example, the condition is constantly \texttt{true}, so we know that we could safely assign the entire expression the type \texttt{num}. Unfortunately, we cannot take advantage of such "degenerate" cases in general, because checking whether the condition is constant is not decidable (the proof of this follows by a reduction from the halting problem).

Another possibility is that the types are not unifiable, but we condition on the resulting type at runtime:

```
define a = if c then 0 else [];
define b = if numeric(a) then a + 1 else length(a) + 1;
```

HM has no way of describing such ad-hoc "unions" between types, so there is no way to specify the type of \texttt{a}. When we extend our system we will explore ways to remedy this.

\subsubsection{\cmark~Polymorphism}

\HMExample{\texttt{define id(x) = x;}}{\input{aux/id.tex}}{\texttt{id :: 'b -> 'b}}

\texttt{id} is a minimal example of an expression with a polymorphic type: Its type indicates that it may be applied to values of any type, to receive a value of the same type. This ability to abstract over parts of the structure of a type is very compelling and is something that we find in the theory of HM but not in the simply typed $\lambda$-calculus.

\subsubsection{\cmark~Higher-Order Functions}

\HMExample{\texttt{define . (f, g) = function (x) f(g(x));}}{\input{aux/compose.tex}}{\texttt{. :: ('e -> 'f, 'd -> 'e) -> 'd -> 'f}}

Function composition is also polymorphic, but inspite of this generality, we may constrain types in terms of each other. Here, the two parameters must be functions, and the domain of the first must coincide with the co-domain of the second.

This interaction between generality and unification is borne out of our use of the \textit{most general} unifier, which represents the minimal set of constraints required for the types to be correct.

\subsubsection{\cmark~Patterns}

\HMExample{\input{aux/folds.tex}}{\input{aux/folds_ast.tex}}{\texttt{length :: ['d] -> num}}

Patterns used in case expressions are also used by the inference algorithm in constraining the types of formal parameters. Here, they are the only indication that \texttt{length} takes list parameters.

\subsubsection{\xmark~Lambda-Bound Polymorphism}

\HMExample{%
  \texttt{define p(a, b) = function (c) c(a, b)}\newline
  \texttt{define f(j) = p(j(true), j(1));}\newline
  \texttt{f(function (x) x);}%
}{\input{aux/lambda_poly.tex}}{\input{aux/lambda_poly_err.tex}}

This valid \textit{Geomlab} program is untypeable in HM. As suggested by the type error, the issue is in the definition of \texttt{f}: Its parameter, \texttt{j}, is applied to both a \texttt{bool} and to a \texttt{num}, which causes a unification error. The trouble is that whilst types may be polymorphic, within the body of a function its parameters may only be instantiated once.

This restriction on the number of instantiations is equivalent to the restriction that types must be in \textit{prenex} form (with all the universal quantifications outermost). With this restriction lifted, it is possible to assign a type to \texttt{f}: ${\forall\pi\ldotp(\forall\alpha\ldotp\alpha\to\alpha)\to((\mathbf{bool},\mathbf{num})\to\pi)\to\pi}$.

The theory supporting such types is referred to as \textit{System F}, and as can be seen, it is more expressive than HM. The downside to this expressivity is that inferring a most general type in \textit{System F} is undecidable.

\subsubsection{\cmark~Let-Bound Polymorphism}

\HMExample{%
  \texttt{let j(x) = x in p(j(true), j(1));}\newline
  \textit{NB.} \texttt{p} \textit{defined as above.}%
}{\input{aux/let_poly.tex}}{\texttt{((bool, num) -> 'e) -> 'e}}

This program stands in contrast to the above, as whilst it evaluates to the same value as the previous program, it \textit{is} typeable. The reason for this is that polymorphic types bound to variables introduced by let-expressions \textit{can} be instantiated multiple times.

The fact that the latter program is typeable and the former is not is of particular interest because in dynamically typed languages, $\mathbf{let}~x = e_1~\mathbf{in}~e_2$ is commonly implemented as sugar for $(\lambda x\ldotp e_2)e_1$.

\subsubsection{\xmark~Infinite Types}

\HMExample{%
\texttt{define f(x) = f;}\newline
\texttt{define g(x) = g(g);}\newline
\texttt{define h(x) = p(h, h);}%
}{\input{aux/infinite.tex}}{\input{aux/infinite_err.tex}}

All these programs yield infinite types, which in our implementation are represented by cyclic data structures.
The implementation detects these cycles, and terminates, printing the types. When printing a cyclic type, if the (nominal) root node of the type is detected again, it is printed as the special variable \texttt{'*}.

\section{Ad-hoc Algebraic Data-types}

Often it is useful to "couple" data together. In many existing statically typed functional programming languages this is achieved by defining a new named data type, but a common technique in \textit{Geomlab} is to use \textit{lists}. For instance, to fully describe a rectangle requires two numbers:

```
define area([width, height]) = width * height;
```

Our existing typechecker infers the type ${\texttt{area :: [num] -> num}}$. The information that rectangles are \textit{pairs} of numbers has been lost. According to this type, \texttt{area} will accept a list of any size, but we know that it is only defined for lists of two elements.

And what if the values differ in type? Consider this (contrived) example of a counter that can be incremented and whose value can be saved. Its state would be comprised of the current count, and the list of saved counts:

```
define push([c, cs]) = [c, c:cs];
define inc([c, cs])  = [c + 1, cs];
```

This is not typeable in HM! It will produce a unification error between \texttt{num} and \texttt{[num]}.

Both of these issues stem from our special treatment of nil and cons. Implicit in the definition of the algorithm is the assumption that they are used only to construct homogeneous, singly-linked lists (A list where every value has the same type). This precludes our idea of using lists to represent arbitrary product types.

Returning to our shapes example, we may want to define \texttt{area}, not just for rectangles, but for other shapes too. Here we define it for squares represented by the length of their side (\texttt{s}).

```
define area([w, h]) = w * h
     | area(s)      = s * s;
```

\begin{wrapfigure}{r}{0.3\textwidth}
  \caption{A union type for shapes.}\label{fig:shape-union}
  \begin{center}
    \texttt{[num, num] + num}
  \end{center}
\end{wrapfigure}

In HM, we unify all parameter patterns together. This means to infer a type for \texttt{area}, we must unify \texttt{num} and cons patterns, which is not possible.

In this section, we will investigate extensions to HM that allow us to specify product and union types in an ad-hoc manner, thus lifting this restriction (Figure\ \ref{fig:shape-union}).

\subsection{R\'emy Encoding}

Introducing the type encoding used by Didier \text{R\'emy}, where each type is a finite union over the constructors in the language.

\subsection{Case Types}

Generalising flags in the \text{R\'emy} encoding to trees where internal nodes represent a choice of what the outer-most constructor is in another type, and leaf nodes represent possible values the flag could take.

\subsection{Rationalisation}

A discussion on decoding the \text{R\'emy} encoding back into a legible type, described in terms of rational trees.

\section{Tagged Variants}

In our \texttt{area} example, when we introduced squares, we were lucky that they had a different structure to our representation of rectangles (one number instead of a pair of numbers), but suppose now we wish to introduce circles, represented by their radius; How would we distinguish between circles and squares?

A common technique is to tag each kind of shape with a unique identifier, and check for these when matching patterns. For this we use \textit{Geomlab}'s atoms as their representation is legible to programmers, and their implementation yields fast equality checks:

```
define area([#rect, w, h]) = w * h
     | area([#square, s])  = s * s
     | area([#circle, r])  = PI * r * r;
```

The issue with this is \texttt{[\#square, s]} and \texttt{[\#circle, r]} both have a type of ${\texttt{[atom, num]}}$: Whilst squares and circles are distinguishable by their tags at the value level, they are not at the type level, so the function defined above would have the same type as this one:

```
define area([#rect, w, h]) = w * h
     | area([#square, s])  = s * s;
```

\begin{wrapfigure}[9]{l}{0.32\textwidth}
  \caption{Tagged union type for shapes.}\label{fig:shape-tagged}
  \begin{Verbatim}
  [#rect, num, num]
+ [#square, num]
+ [#circle, num]
  \end{Verbatim}
\end{wrapfigure}

This is clearly not ideal, as the latter function will throw an error at runtime if applied to a circle. To get around this, we could lift atoms to the type level: Furnish every atom value with a corresponding type that only it inhabits. Then squares will have type \texttt{[\#square, num]}, and circles \texttt{[\#circle, num]} (Figure\ \ref{fig:shape-tagged}).

\subsection{Wildcard Constructors}

A technique to get around the "finite constructor" limitation of the R\'emy encoding whereby if we have an infinite family of constructors (like multi-arity functions or atoms) we have a constructor for each member of the family, as well as a wildcard constructor to capture our knowledge about the rest of the constructors in the family.

\section{Recursive Types}

In HM, the list was a recursive type that we had built in support for. We lost this support when we stopped treating $\texttt{[]}$ and $\texttt{(:)}$ as special, related constructors. Now, if we try to encode the a list of type \texttt{'a}, we get: \texttt{[] + ('a':'l)} where \texttt{'l} refers back to the type we are defining, yielding an infinite (cyclic) type, which our typechecker balks at. Similarly, an attempt to construct a representation of binary trees using our existing machinery may look something like this:

```
#leaf              { Leaves }

[#branch, l, x, r] { Branch with datum `x`
                   , left sub-tree `l`
                   , and right sub-tree `r`
                   }
```

But again, \texttt{l} and \texttt{r} have the same type as the branch they are contained in. The ability to specify ad-hoc recursive types would make such expressions typeable (Figure\ \ref{fig:rec-type}).

\begin{figure}[htbp]
  \caption{Using ad-hoc recursive types. Fixed points are introduced by the \texttt{(...)*} operator, and we use de-Bruijn indices to represent recursion sites.}\label{fig:rec-type}
  \begin{Verbatim}
list 'a ::= ([] + ('a:'0))*
tree 'a ::= ([#branch, '0, 'a, '0] + #leaf)*
  \end{Verbatim}
\end{figure}

\subsection{Type Annotations}

We will mandate that recursive definitions must have type annotations to side step the issues of inferring such types. Motivating examples for this decision will include definitions of \texttt{reverse} and \texttt{append}, whose types, whilst sound, are useless.

\subsection{Circular Unification}

Recursive types can occur even without recursive definitions, this section will show an expression that does this, and the solution, in the form of Huet's circular unification algorithm.

\section{Related Work}

Aiken and Wimmers work on conditional types (A type $\tau?\sigma$ that is $\tau$ when $\sigma\neq\varnothing$ and is $\varnothing$ itself otherwise).

Mishra and Reddy's work on Declaration-free Typing (using discriminative unions).

Marlow and Wadler's work on a similar type system for Erlang (no higher-order functions).

W Swierstra's Data-types a la carte which builds a similar type system, using Haskell's type class machinery.

\section{Future Work}
Everything I didn't have time to fully flesh out:
\begin{itemize}
  \item Type inference of recursive types.
  \item Useful errors.
  \item Type level booleans.
\end{itemize}

\section{References}

\bibliography{references}

\appendix

\section{Listings}

Code for the Parser, Lexer, and Type Inference algorithm.

\section{Tests}

Accompanying unit tests.
